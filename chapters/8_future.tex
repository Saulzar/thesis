\chapter{Conclusions~and~Future~Work}
\label{chap:future} 


\section{Future work}
\subsection{Ensemble training and uncertainty estimation}

There exist a number of uncertainty measures specifically developed for object detection based on Bayesian \gls{NMS} \cite{Harakeh}, test time augmentation {Wei2018} and of particular interest based on ensembles \cite{Le2018}. Some discussion in section--\ref{sec:example_selection}. 

K-fold cross-validation is proposed as a future method to improve data usage. It can be used for ensemble based predictions on new images with uncertainty estimation, unbiased reviewing and machine assisted verification to check for mistakes and improved accuracy in testing by testing against the full dataset.

In conflict with our desire to use high resolution images for annotation clarity, ensembles, example selection, and interface responsiveness would all benefit from use of lower resolution images. More experimentation is necessary to determine the best trade off, which seems likely to depend on the dataset.

\subsection{Domain specific applications, counting wildlife}

One promising application for \gls{VBA} has been to counting wildlife, where the annotation tool has been used for verified counting of Antarctic wildlife. A number of limitations were discovered, such as efficiency issues with the user interface in the presence of very large numbers of object, and the difficulties created by artificial splitting of images. Addressing efficiency is very straightforward, but a way of allowing the user to divide up very large images would seem beneficial.

A number of metrics and image selection heuristics were added to attempt to aid experimentation with time series images. Expanding on these heuristics and providing better methods for exploring and sorting images would be beneficial for studying these kind of images. Adding image level classification would also be useful for sorting and managing datasets, for example discarding images with poor visibility automatically would be possible if discarded images are be labelled and used for learning.

\subsection{Higher level forms of object detection}

\begin{figure*}[h!]
\begin{subfigure}[t]{1.0\linewidth}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/future/tree_cutpoint.pdf}
  \caption{} 
\end{subfigure}

\begin{subfigure}[t]{1.0\linewidth}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/future/tree_branches.jpg}
  \caption{} 
\end{subfigure}
\caption{Ongoing work into annotating trees in (a) cut-point detection, (b) tree structure skeleton extraction }
\label {fig:future_trees}
\end{figure*}

Bounding boxes have limits for object detection, they only very loosely fit an object. Some objects cannot be described well by bounding boxes at all. Tree branches are fit by bounding boxes very badly; they're very long, and it's not always clear where they start and stop. Future work will focus on other kinds of object detection, and the ability to pick the type for the task at hand.

Recent work in object detection \cite{Zhou2019} or \cite{Law2018}, both successors to the RetinaNet detector \cite{Wang2017} used in this work, have shown that both the anchor box approach, and \gls{NMS} is unnecessary. In \cite{Zhou2019}, local maxima in a single a heat map is used to detect objects, all other parameters are regressed, allowing for simple extension to a range of different types of object detector.

The branches dataset used as an example in this work is a trial for detecting cut positions. Figure~\ref{fig:future_trees} shows two directions in annotation of tree structures, cut point estimation and skeletal extraction for robotic pruning applications. Skeleton estimation on tree structures can be adapted from methods used for road network extraction \cite{Li2018}, shape estimation \cite{Jiang2019a} or polygon extraction \cite{Acuna2018}, and can work well within the \gls{VBA} approach.

One barrier preventing research into new forms of object detection is annotation. Models for detection can be integrated with the verification based annotation approach described in this thesis for experimentation on new forms of object detection.

\subsection{Annotating uncertainty}

In future the ability to annotate images based on uncertainty may be a useful approach, as a means of calibrating confidence and for the purposes of weighting examples in the training process. As opposed to epistemic uncertainty, aleatoric uncertainty can be estimated directly (by a \gls{NN} for example by regression).  

This kind of uncertainty annotation may be also useful in weighting training loss, where the network can place more weight on hard, yet unambiguous examples. The use of Focal Loss means that examples which fail to classify well are weighted much more highly, if these examples are ambiguous because of shadow or lack of resolution - their contribution to the training will be purely as noise.

Hard examples are often cited as being the most useful for an object detector, but if the hard examples are not really hard examples, because they are also visually ambiguous or uncertain (high aleatoric uncertainty) then their usefulness as a learning target might be less, but still possesses value for use in validation and calibration.



\subsection{User verification and testing}
\label{sec:user_verification}

The risk of algorithmic bias brings into the question the quality of a dataset annotated with a \gls{VBA} system.  In order to combat algorithmic bias when a human annotator becomes fatigued, it is proposed that a certain level of \emph{generated} mistakes can be included. Which a user is either forced to fix before they may continue, or is logged as a measure of the user's trustworthiness. For example adding \emph{deliberate} errors into provided detections, such as false positives, false negatives by removing very high confidence detection, or localisation errors by transform box of high confidence detection. 


\subsection{Software improvements}

There are a range of general software improvements to improve usability and prepare for release to a wider audience. Some plans are detailed in chapter~\ref{chap:design}, including: streamlining detection to avoid the need for selecting manual thresholds, simplifying the interface, easy deployment to cloud based systems, integrating and exposing object detection configuration parameters to the user interface and integration of visualisation for metrics.

\section{Conclusion}